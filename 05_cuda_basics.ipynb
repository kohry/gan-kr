{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KcviuZ92K-0Y"
   },
   "source": [
    "# CUDA 기본 - 간단한 예제\n",
    "\n",
    "GAN 첫걸음, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8-fk3XZeK0hP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G40AKirRhOcs"
   },
   "source": [
    "## Numpy와 파이썬 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TyZQfwoLKyaI"
   },
   "outputs": [],
   "source": [
    "# 정사각형 행렬의 크기\n",
    "size = 600\n",
    "\n",
    "a = numpy.random.rand(size, size)\n",
    "b = numpy.random.rand(size, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RiWSaKT3b57n",
    "outputId": "343f4028-6700-4a4e-8dd1-2e98763ea861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 13.2 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "x = numpy.dot(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nJe4_VVpYn_i",
    "outputId": "b9c62d2f-5315-40fb-f129-52eb544c6a09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 3min 20s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "c = numpy.zeros((size,size))\n",
    "\n",
    "for i in range(size):\n",
    "  for j in range(size):\n",
    "    for k in range(size):\n",
    "      c[i,j] += a[i,k] * b[k,j]\n",
    "    pass\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7IsDaKcoNFLR"
   },
   "source": [
    "## GPU에서 텐서 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1H1U4grjNL_m",
    "outputId": "a0480efe-0ace-413c-a296-6ffa90ae02ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.cuda.FloatTensor'"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU에서 텐서 생성\n",
    "\n",
    "x = torch.cuda.FloatTensor([3.5])\n",
    "x.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ITLReJU_bR6-",
    "outputId": "d4a6ef29-53f9-442b-80cd-cdae308f8168"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서가 GPU에 설정되어 있는지 확인\n",
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OKCqHZ0zbcIn",
    "outputId": "fceed783-9865-40e5-e15a-3f2629d65df6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12.2500], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU를 통해 텐서 계산\n",
    "\n",
    "y = x * x\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yF8mW5kqiPOZ"
   },
   "source": [
    "## CUDA 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pg78pR2vM_U2"
   },
   "outputs": [],
   "source": [
    "# numpy 행렬로부터 cuda 텐서 생성\n",
    "\n",
    "aa = torch.cuda.FloatTensor(a)\n",
    "bb = torch.cuda.FloatTensor(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "1_7JODnbF2gw",
    "outputId": "f5017e4b-578b-45b3-a95a-e7325f62d84c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 29.97 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 74.6 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "cc = torch.matmul(aa, bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ba7Ggq_6M5Bb"
   },
   "source": [
    "## 일반적인 CUDA 설정과 확인 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "lU86giDzM3Dv",
    "outputId": "da312c5b-ecfb-4e38-a6fa-4ccf475d7de9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda: Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CUDA가 이용가능한지 확인\n",
    "# 가능하다면, 기본 텐서 타입을 cuda에 설정\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "  print(\"using cuda:\", torch.cuda.get_device_name(0))\n",
    "  pass\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "05_cuda_basics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
